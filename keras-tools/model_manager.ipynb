{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to manage keras models (loading, saving, training, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from tqdm import tqdm  # progress bars\n",
    "import numpy as np\n",
    "import os, subprocess, sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********\n",
    "Add logcosh loss function if using Keras 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logcosh(y_true, y_pred):\n",
    "    \"\"\"Logarithm of the hyperbolic cosine of the prediction error.\n",
    "    `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n",
    "    to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n",
    "    like the mean squared error, but will not be so strongly affected by the\n",
    "    occasional wildly incorrect prediction.\n",
    "    # Arguments\n",
    "        y_true: tensor of true targets.\n",
    "        y_pred: tensor of predicted targets.\n",
    "    # Returns\n",
    "        Tensor with one scalar loss entry per sample.\n",
    "    \"\"\"\n",
    "    def _logcosh(x):\n",
    "        return x + keras.backend.softplus(-2. * x) - keras.backend.log(2.)\n",
    "    return keras.backend.mean(_logcosh(y_pred - y_true), axis=-1)\n",
    "\n",
    "try:\n",
    "    keras.objectives.logcosh = logcosh\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_model_structure = '''\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(len(input),)))\n",
    "model.add(Activation('tanh')) # relu, elu, sigmoid\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(output)))\n",
    "model.add(Activation('softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Load models and their configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(path, extension='.h5'):\n",
    "    model_names = os.listdir(path)\n",
    "    model_names = [n for n in model_names if n.endswith(extension)]\n",
    "    models = []\n",
    "    model_configs = []\n",
    "    \n",
    "    for load_version, model_name in enumerate(tqdm(model_names)):\n",
    "        models.append(load_model('{}/'.format(path)+model_name))\n",
    "        model_configs.append(models[-1].get_config())\n",
    "        \n",
    "    print('\\nLoaded {} models from {}'.format(len(models),path))\n",
    "    return models, model_names, model_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Save out models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(path, models, model_names=None):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    if model_names:\n",
    "        if len(model_names)==len(models):\n",
    "            for m, n in tqdm(zip(models, model_names)):\n",
    "                m.save('{}/{}.h5'.format(path, n))\n",
    "        else:\n",
    "            raise('Supply a name for each model {} vs {}'.format(len(model_names), len(models)))\n",
    "    else:\n",
    "        for idx, m in enumerate(tqdm(models)):\n",
    "            m.save('{}/{}.h5'.format(path, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Filter duplicate configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(model_configs):\n",
    "    unique = []\n",
    "    configs = copy.copy(model_configs)\n",
    "    for config in tqdm(configs):\n",
    "        configs.remove(config)\n",
    "        compare = [config == c for c in configs]\n",
    "        if not np.sum(compare):\n",
    "            unique.append(config)\n",
    "        \n",
    "    print('\\n{} unique model configs'.format(len(unique)))\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "Compile models from configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_from_configs(model_configs, savepath=None, losses=['logcosh'], optimizers=['adagrad'], metrics=['accuracy']):\n",
    "    models = []\n",
    "    \n",
    "    for loss in losses:\n",
    "        for opt in optimizers:\n",
    "            for idx, config in enumerate(tqdm(model_configs)):\n",
    "                model = keras.Sequential.from_config(config)\n",
    "                model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "                models.append(model)\n",
    "                if savepath:\n",
    "                    if not os.path.exists(savepath):\n",
    "                        os.mkdir(savepath)\n",
    "                    model.save('{}/{}-{}-{}.h5'.format(path, loss, optimizer, idx))\n",
    "                    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_models(models, savepath=None, losses=['logcosh'], optimizers=['adagrad'], metrics=['accuracy']):\n",
    "    _models = []\n",
    "    \n",
    "    for loss in losses:\n",
    "        for opt in optimizers:\n",
    "            for idx, config in enumerate(tqdm(models)):\n",
    "                model = keras.Sequential.from_config(config)\n",
    "                model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "                _models.append(model)\n",
    "                if savepath:\n",
    "                    if not os.path.exists(savepath):\n",
    "                        os.mkdir(savepath)\n",
    "                    model.save('{}/{}-{}-{}.h5'.format(path, loss, optimizer, idx))\n",
    "                    \n",
    "    return _models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Load in training data from 'trainN.in' and 'trainN.out' (data formatted as lists or numpy arrays), for N in nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_path(path, nums=[]):\n",
    "    if not isinstance(nums, list):\n",
    "        nums = list(nums)\n",
    "    \n",
    "    input, output = [], []\n",
    "    \n",
    "    for num in nums:\n",
    "        print(\"Reading train{}.in\".format(num))\n",
    "        with open('{}/train{}.in'.format(path, num), \"r\") as f:\n",
    "            train_in = f.read().split('\\n')\n",
    "            train_in = [np.fromstring(i.lstrip('[]').replace(',',' '),sep=' ') for i in tqdm(train_in[:-1])]\n",
    "\n",
    "        print(\"Reading train{}.out\".format(num))\n",
    "        with open('{}/train{}.out'.format(path, num), \"r\") as f:\n",
    "            train_out = f.read().split('\\n')\n",
    "            train_out = [np.fromstring(i.lstrip('[]').replace(',',' '),sep=' ') for i in tqdm(train_out[:-1])]\n",
    "        \n",
    "        if len(train_in) != len(train_out):\n",
    "            print('train{}.in'.format(num), len(train_in))\n",
    "            print('train{}.out'.format(num), len(train_out))\n",
    "            raise('lengths do not match')\n",
    "        \n",
    "        print('Adding train{}.in'.format(num))\n",
    "        for line in tqdm(train_in):\n",
    "            input.append(line)\n",
    "        print('Adding train{}.out'.format(num))\n",
    "        for line in tqdm(train_out):\n",
    "            output.append(line)\n",
    "            \n",
    "    return np.array(input), np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Load in training data from numpy saved arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_numpy(path, input_file='train_in.npy', output_file='train_out.npy'):\n",
    "    print('Loading from {}'.format(path))\n",
    "    train_in = np.load('{}/{}'.format(path, input_file))\n",
    "    train_out = np.load('{}/{}'.format(path, output_file))\n",
    "    \n",
    "    print('input {}, length {}'.format(input_file), len(train_in))\n",
    "    print('output {}, length {}'.format(output_file), len(train_out))\n",
    "    if len(train_in) != len(train_out):\n",
    "        raise('lengths do not match')\n",
    "    \n",
    "    return input, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def shuffle(input, output):\n",
    "    data = list(zip(input, output))\n",
    "    random.shuffle(data)\n",
    "    train_in, train_out = [],[]\n",
    "    \n",
    "    for line in tqdm(data):\n",
    "        train_in.append(line[0])\n",
    "        train_out.append(line[1])\n",
    "        \n",
    "    return np.array(train_in), np.array(train_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Split data into training and testing groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_in, train_out, test_ratio):\n",
    "    test_size = int(test_ratio * len(train_in))\n",
    "\n",
    "    x_train = train_in[:-test_size]\n",
    "    y_train = train_out[:-test_size]\n",
    "\n",
    "    x_test = train_in[-test_size:]\n",
    "    y_test = train_out[-test_size:]\n",
    "\n",
    "    print('Training on {} samples, testing on {} samples'.format(len(train_in), test_size))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_models(models, x_train, y_train, epochs=5, batch_size=2**15, verbose=0, validation_split=0.08):\n",
    "    histories = []\n",
    "    \n",
    "    print('Training on batches of {} for {} epochs'.format(batch_size, epochs))\n",
    "    \n",
    "    for idx, model in enumerate(tqdm(models)):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=verbose,\n",
    "                            validation_split=validation_split)\n",
    "\n",
    "        histories.append(history)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_models(models, x_test, y_test, batch_size=2**15, verbose=0):\n",
    "    scores = []\n",
    "    \n",
    "    for idx, model in enumerate(tqdm(models)):\n",
    "        score = model.evaluate(x_test, y_test,\n",
    "                               batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "        scores.append(score)\n",
    "        print('Model {} Score: {}'.format(idx, score))\n",
    "        \n",
    "    for s in scores:\n",
    "        yield s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_eval(models, x_train, y_train, x_test, y_test, epochs=5, batch_size=2**15, verbose=0, validation_split=0.08):\n",
    "    print('Training and evaluating models')\n",
    "    _models, scores = [], []\n",
    "    for model in tqdm(models):\n",
    "        _models.append(train_models(model, x_train, y_train, epochs, batch_size, verbose, validation_split))\n",
    "        scores.append(eval_models(model, x_test, y_test, batch_size, verbose))\n",
    "    \n",
    "    return _models, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
